JHU Machine Learning - Model Based Prediction

Iris Data Example

```{r}
data("iris"); library(ggplot2)
names(iris)
```
```{r}
table(iris$Species)
```

Create test/training sets:
```{r}
library(caret)
inTrain <- createDataPartition(y=iris$Species, 
                               p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
```

Build Predictions
```{r}
#linear dicriminant analysis
modlda <- train(Species ~., data=training, method="lda")
#naive bayes 
modnb <- train(Species ~., data=training, method="nb")
plda <- predict(modlda, testing)
pnb <- predict(modnb, testing)
table(plda, pnb)
```
- tabling the two models against each other shows that the two models are generally in agreement with one another, except for the 2 values

Comparison of results
```{r}
equalPredictions = (plda==pnb)
qplot(Petal.Width, Sepal.Width, colour=equalPredictions, data=testing)
```

## Notes and further reading

* [Introduction to statistical learning](http://www-bcf.usc.edu/~gareth/ISL/)
* [Elements of Statistical Learning](http://www-stat.stanford.edu/~tibs/ElemStatLearn/)
* [Model based clustering](http://www.stat.washington.edu/raftery/Research/PDF/fraley2002.pdf)
* [Linear Discriminant Analysis](http://en.wikipedia.org/wiki/Linear_discriminant_analysis)
* [Quadratic Discriminant Analysis](http://en.wikipedia.org/wiki/Quadratic_classifier)
