JHU Machine Learning - Predicting with Trees

Iris dataset example

```{r}
data(iris); library(ggplot2)
names(iris)
```
```{r}
table(iris$Species)
```

Separate data set into training/test sets

```{r}
library(caret)
inTrain <- createDataPartition(y=iris$Species, p=.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(testing)
```

Plot the training set
```{r}
qplot(Petal.Width, Sepal.Width, colour=Species, data=training)
```

```{r}
library(caret)
modFit <- train(Species ~., method="rpart", data=training)
print(modFit$finalModel)
```
Plotting the classification tree
```{r, }
plot(modFit$finalModel, uniform=TRUE,
     main="Classification Tree")
text(modFit$finalModel, use.n = TRUE, all=TRUE, cex=.8)
```

Pretty form of the dendrogram:
```{r}
library(rattle)
fancyRpartPlot(modFit$finalModel)
```

Predicting new values:

```{r}
predict(modFit, newdata=testing)
```

Links:

* [Introduction to statistical learning](http://www-bcf.usc.edu/~gareth/ISL/)
* [Elements of Statistical Learning](http://www-stat.stanford.edu/~tibs/ElemStatLearn/)
* [Classification and regression trees](http://www.amazon.com/Classification-Regression-Trees-Leo-Breiman/dp/0412048418)

