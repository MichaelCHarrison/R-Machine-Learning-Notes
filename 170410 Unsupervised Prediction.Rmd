JHU Machine Learning - Unsupervised Prediction

Using Iris data:
- ignoring species labels
```{r}
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
                               p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(testing)
```

*Cluster with k-means*
```{r}
#set clusters, ignoring Species variable
kMeans1 <- kmeans(subset(training, select=-c(Species)), centers=3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width, Petal.Length, colour = clusters, data=training)

```

*Compare to real labels*
```{r}
table(kMeans1$cluster, training$Species)
```

*build predictor*
```{r}
#rpart = classification tree
modFit <- train(clusters ~., data=subset(training, select = -c(Species)), 
                method="rpart")
table(predict(modFit, training), training$Species)
```

*Apply on Test*
```{r}
testClusterPred <- predict(modFit, testing)
table(testClusterPred, testing$Species)
```

*Final Notes*
- the cl_predict function in the lcue package provides similar functionality
- beware over-interpretation of clusters!
- additional information:
* This is one basic approach to [recommendation engines](http://en.wikipedia.org/wiki/Recommender_system)
* [Elements of statistical learning](http://www-stat.stanford.edu/~tibs/ElemStatLearn/)
* [Introduction to statistical learning](http://www-bcf.usc.edu/~gareth/ISL/) 